<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<html>
<head>
<title>
High precision clock distribution</title>
</head>
<body background="grey.jpg">
<h1 align=center>
<A NAME="4"></A>Chapter 4 : High precision clock distribution</h1>

This chapter describes the background to the clock distribution
implemented as part of the research of this thesis. It consists of a
section describing the nature of the timestamping and synchronisation
provided in the Pandora system, with its associated disadvantages;
proposals for possible solutions to improve on the original Pandora
system; an examination of the proposals; a look at the requirements
necessary for precise, accurate clock distribution; a summary of the
technology enabling the fulfillment of these requirements.

<p>
<A NAME="4.1"></A><h3>
4.1 Pandora timestamping and synchronisation
</h3>
<p>


<p>
The Pandora system provides capture and replay of many real-time video
and audio streams. One of the major problems associated with handling
this real-time data is the synchronisation of replay of related
streams. The Pandora system uses an old approach to handling
synchronisation --- that is, it trusts synchronisation will just happen. The following sections
describe in detail how this system works, and in what circumstances it
fails to work.

<p>
<A NAME="4.1.1"></A><h4>
4.1.1 Pandora timestamping
</h4>
<p>


<p>
All the continuous media streams in Pandora are timestamped by the
data sources with a 32-bit microsecond timestamp. On a standard
Pandora box these timestamps are local to the data source which
created the data, and as they are created by low priority transputer
processes, their granularity is 64 microseconds. The only
synchronisation point is at reset, when the Pandora system's
transputers reset their clocks to 0. Indeed, the timestamps given to
the data are times relative to the time of the last reset of their
source and not relative to the time the stream was started.

<p>
The timestamps are not used by the Pandora boxes themselves at
all. The data is timestamped for the sake of completeness. Instead,
the Pandora systems rely on low jitter in streams and low inter-stream
latency differences to provide synchronisation of real-time video and
audio streams, and the timestamps are just ignored. This places the
burden of synchronisation on the systems which must transport the data
from source to sink, of which the hardest to manage is the network.

<p>
The network that Pandora was designed to use, the CFR, can cope quite
well with the requirements of low jitter and low inter-stream latency
with the network software implementation described in chapter
<A HREF="pandora_network_software_implementation.html#3">3</A>. Indeed, Pandora boxes work very
well together, and synchronization between live video and audio
sources is well within user acceptable limits.

<p>
<A NAME="4.1.2"></A><h4>
4.1.2 Synchronisation problems
</h4>
<p>


<p>
Having said that Pandora boxes perform well when networked in
synchronisation terms, there can be problems caused by the network
itself, or by using a Pandora box to comunicate with a non-Pandora system:

<p>
<UL>


<p>
<LI>Videomail repository


<p>
One of the problems which arose with running the Pandora system in
conjunction with a videomail repository was synchronisation of the
replay of the audio and video streams which make up a piece of
videomail. Unlike a Pandora box, which replays data when it receives
it, the repository must maintain a timetable for the replay of data it
records. As the timestamps on the audio and video are generated by
their respective sources, and no synchronisation of the sources inside
a Pandora box is performed, the timestamps of contemporary audio and
video segments need not be, even approximately, equal, so the
timestamps themselves cannot be used as the full solution.

<p>
The actual solution chosen by the author of the videomail repository
software was to calculate the offset between the timestamps of the
audio and video segments at the start of recording, and to assume that
the drift in the clocks of the data sources can be neglected over the
time span of a videomail message. The initial offset between the
timestamps of the different steams being recorded is calculated by
waiting until both streams are active and sending data, then to
evaluate the difference between the timestamps of the next segments of
data received on both streams. The replay of data is performed by
trying to maintain the offset between the timestamps of the two
streams at all times.

<p>
This mechanism works well with Pandora boxes connected over a single
CFR network, where the startup of streams' transmission of data is
immediate and not subject to initial variations. However, when Pandora
boxes on different CFR networks, interconnected with the Cambridge
Backbone Network (CBN) <B><A HREF="bibliography.html#Bib16">[16]</A></B> as a backbone network, were
used, it was found that the synchronisation of streams became
erratic. This problem is due to the jitter introduced during the
start-up phase of data transmission by the bridges between the
networks. For a short time after a connection has been made between
the Pandora box and the videomail repository on different networks,
the intervening bridges do not handle the data sent on the connection
consistently. This is either due to jitter introduced by the upper
protocol layers managing the new connection, or perhaps due to the
order in which a connection is initialised by the bridges.  Whatever
the case, the Pandora box sending the video and audio data would end
up retrying the first few buffers for transmission. With the bridges
not being ready to accept the data, the retries could take many
milliseconds, forcing the audio and video buffers to fill. When one of
these buffers fails in its retry attempts, all the data is discarded,
and new data read in. If at this stage the bridge starts to behave
normally, and both audio and video streams transmit successfully,
there can be an additional offset between the timestamps of the audio
and video segments transmitted. If, for example, the audio data is
discarded due to its retry strategy failing, but the video data (being
lower priority) gets through, the first video data to arrive at the
repository is much older than the first audio data. By virtue of the
mechanism chosen by the repository for calculating the inter-stream
timestamp offsets, the value obtained is wrong by this extra age.

<p>
As a workaround, the repository now waits until both streams are
active, waits another second, and then examines the two timestamps of
the next video and audio segments to arrive.

<p>
</LI>
<LI>Bridges

<p>
Two forms of bridge between the networks were used in the
internetworking environment during this research. The first form was
block-forwarding, the second cell-forwarding. Cell-forwarding bridges
transmit cells on the destination network as soon as possible after
they are received on the source network. These bridges have a small
effect on the transit time for single cells, which is not noticeable
in general in live or recorded streams.

<p>
Block-forwarding bridges reassemble cells received on the source
network into blocks, then segment the blocks and transmit the new
cells on the destination network. This form of bridge is generally used
between networks with different cell sizes (the ATM switch network has
48-byte cells, the CFR and CBN have 32-byte packets), or when different
segmentation processes are required on the different networks (MDL/FDL
or AAL5, for example). These bridges introduce extra delay in the
transit time of a segment of data, proportional to the number of cells
in the block. So video data has a much longer transit time than audio
data. This is true of Pandora streams anyway, but the additional delay
caused by the bridges in practice leads to disconcerting
synchronisation lapses between live video and audio streams, which is
also recorded by the videomail repository.

<p>


<p>

</LI>
</UL>


<p>
<A NAME="4.2"></A><h3>
4.2 Improving synchronisation
</h3>
<p>


<p>
The beauty of the Pandora system design is its simplicity, and a
solution to the problems of synchronisation should attempt to retain
the simplicity. Three possible solutions are presented here in the
following sections: a timestamp database; synchronisation agents and
managers; clock synchronisation.

<p>
<A NAME="4.2.1"></A><h4>
4.2.1 A timestamp database
</h4>
<p>


<p>
Synchronisation of a number of streams requires a mapping between the
individual streams' timestamps. A possible solution is to generate a
mapping from the local data sources to a fixed reference clock, and
this can be performed by requiring the data sources to inform a
timestamp database at regular intervals what its local time is. If all
data sources report to the same timestamp database then timestamps
from streams from a source can be mapped onto timestamps from streams
from a different source.

<p>
This removes any problems involved in the synchronising of recorded
streams, but does not help much with the playing of live data. An
enhancement to the system would allow data sinks to request the timestamp
relationships of the data sources in real-time, and so a mapping from
their own clocks to the data source timestamps could be made, and the
streams therefore synchronised.

<p>
<A NAME="4.2.2"></A><h4>
4.2.2 Synchronisation agents and managers
</h4>
<p>


<p>
The problems with synchronising streams only occur if different
streams have different transit times from source to sink. If these
transit times can be calculated, the difference in delays can be
removed before the data is replayed or recorded, achieving
synchronisation.  This can be performed using synchronisation agents
as in <B><A HREF="bibliography.html#Bib11">[11]</A></B>. All the data which needs to be synchronised is
sent from the sources to a local synchronisation agent. The jitter in
the transit time between the source and the agent must be kept to a
minimum, ideally zero. The synchronisation agent can then either
combine the data into a single transmission, or record the timestamp
offsets and transmit these and the data, to a destination
synchronisation agent. This agent forwards the data to the data sinks
with the appropriate delays between segments, using the knowledge of
the timestamps given to it by the source synchronisation agent, this
time with the jitter in distribution from the agent to the data sink
being a minimum. A very similar device is the synchronisation manager
(<B><A HREF="bibliography.html#Bib64">[64]</A></B>), where data sources and data sinks provide stream
information to the manager, which collates the information before
providing feedback to the sources and sinks to maintain
synchronisation. Others, e.g. <B><A HREF="bibliography.html#Bib62">[62]</A></B> and <B><A HREF="bibliography.html#Bib47">[47]</A></B>, have
investigated and implemented similar systems.

<p>
<A NAME="4.2.3"></A><h4>
4.2.3 Clock synchronisation
</h4>
<p>


<p>
A common mechanism used for timestamping data, for example file
acceses, over a network filing system is by synchronising the clocks
of the file servers (<B><A HREF="bibliography.html#Bib38">[38]</A></B>, <B><A HREF="bibliography.html#Bib28">[28]</A></B>). This scheme can
be extended to the timestamping of real-time data, for recording, live
replay and replay of recordings.

<p>
The only requirement is that all data sources and data sinks
synchronise their clocks, using a clock distribution
mechanism. Data sinks can then replay data a fixed time offset from
the data timestamps. Synchronisation occurs because the clocks of the
data sources were synchronised, so the data is timestamped with the
same global clock, and because the clocks of the data sinks are synchronised.

<p>
<A NAME="4.3"></A><h3>
4.3 Examination of the possible solutions
</h3>
<p>


<p>
The three proposed systems differ in their complexity of
implementation, their impact on the data paths, and their
effectiveness:

<p>
<A NAME="4.3.1"></A><h4>
4.3.1 Timestamp database
</h4>
<p>


<p>
The timestamp database requires a large database of all the data
sources and data sinks to be kept, with a history of the timestamp
offsets being kept so repositories can correctly map their recorded
timestamps of different streams together. The data paths are
unaffected, although connections from each data source and data sink
to the timestamp database must be maintained. For reliable service,
multiple copies of the database should be kept in case one fails, in
which case the system becomes more complex and more connections are
required, impacting on the data performance. The effectiveness of the
timestamp database also depends on the jitter in sending the timestamp
messages to the database from the sources, and from the database to
the sinks. Since this jitter is the source of the synchronisation
problem, the effectiveness of the solution must be in doubt.

<p>
<A NAME="4.3.2"></A><h4>
4.3.2 Synchronisation agents and managers
</h4>
<p>


<p>
The synchronisation agents are perhaps the most Pandora-like solution
to the synchronisation problem, as they would be a single device
managing external variations locally. Even so, they would be
complicated at the replay end, as they must manage the scheduling of
data transmissions to the sinks for replay purposes. In addition, all
data which requires synchronisation must travel through the same
synchronisation agents, and so the network bandwidth available to the
synchronisation agents will have a large impact on the performance of
the streams. Finally, provided the synchronisation agents are local to
the data sources and sinks, and hence jitter from sources to agents
and from agents to sinks is kept small, they should be effective in
synchronising streams. Synchronisation managers are less effective in
a multi-stream system where streams may be required to go to multiple
destinations: combining feedback from all the sources and sinks grows
in complexity as the sources and destinations increase in number. They
also do not fit in well with the Pandora style of simplicity and local
handling of streams.

<p>
<A NAME="4.3.3"></A><h4>
4.3.3 Clock synchronisation
</h4>
<p>


<p>
Distributing a clock of a suitable accuracy to each of the data
sources and sinks may require individual connections from the sources
and sinks to a clock distribution service. In this case the jitter in
the communication of the clock from the distribution server to a
client must be removed, or the effectiveness of the distribution will
be reduced. Fortunately, when the local clock is synchronised to the
global clock, the data paths are unaffected by the clock distribution
method, and inter-stream synchronisation can occur fairly painlessly if the data
sinks can schedule the replay of their incoming data according to the
local clock.

<p>
Clock synchronisation has been examined many times before, with
master-slave synchronisation (e.g. <B><A HREF="bibliography.html#Bib74">[74]</A></B>), fully distributed
synchronisation (e.g. <B><A HREF="bibliography.html#Bib44">[44]</A></B>, <B><A HREF="bibliography.html#Bib63">[63]</A></B>), and emphasis on
fault tolerance (<B><A HREF="bibliography.html#Bib67">[67]</A></B>). For the experimental Pandora system
on interconnected CFRs any fault tolerance is a luxury, but to support
the precision of the Pandora timestamps (one microsecond) precise
global clock distribution is required. This implies the clock source
should have a precision and accuracy of one microsecond, and need not
be elected, but can be fixed. Different CFRs can have seperate clock
sources synchronised by some other mechanism to achieve microsecond
accuracy. (For inter-stream synchronisation the full accuracy is not
required, but it an be used effectively for performance evaluation of
the system.)

<p>
The global clock distribution system can run hierarchically, with the
fixed reference clock synchronising a few clients, which in turn act
as servers for more clients, down to the data source and sinks.In the
Pandora system an obvious clock synchronisation point is the network
interface. This can then serve the data sources and sinks inside the
Pandora box.

<p>
<A NAME="4.4"></A><h3>
4.4 Requirements for precise distributed clocks
</h3>
<p>


<p>
There are four requirements for accurately distributing a precise
clock: a precise time source; a consistent local clock; an accurate
distribution mechanism; a good logical clock model.

<p>
<A NAME="4.4.1"></A><h4>
4.4.1 Precise time source
</h4>
<p>


<p>
The precision of a distributed clock depends primarily on the
precision of the time sources from which it is derived. Greater
precision than that of the time source cannot be achieved, although if
the distribution mechanism throws away some of the precision given by
the time source, that precision is also lost to the distributed clock.

<p>
<A NAME="4.4.2"></A><h4>
4.4.2 Consistent local clock
</h4>
<p>


<p>
Once a precise clock value is accurately known by a system, that
system must be able to maintain the accuracy of its knowledge of the
distributed clock using its own local clock. If this local clock has a
steady drift then this can be accounted for by the logical clock
model. If the local clock is inconsistent, and drifts randomly over
short intervals of time (less than the time intervals between
distribution messages from the clock server, for example), this cannot be removed
by the clock model, and so it will affect the accuracy of the local
knowledge of the global clock.

<p>
<A NAME="4.4.3"></A><h4>
4.4.3 Accurate distribution mechanism
</h4>
<p>


<p>
In order to distribute the global clock to a client to a certain
accuracy, the transit time of messages from the server to the client
must either be known accurately, be accurately calculable, or be
statistically such that the logical clock can remove any unknown in
the transit time. If this constraint is not met, the logical clock
model cannot remove the inaccuracy of the transit time of messages
from the server to the client from the local knowledge of the global
clock.

<p>
The transit time is defined to be the time between a time
server or client requesting a transmission, and it arriving at the
local-clock-reading process at its destination.

<p>
<A NAME="4.4.4"></A><h4>
4.4.4 Logical clock model
</h4>
<p>


<p>
The logical clock model has three inputs: a local clock; messages from
the server indicating the global clock value; estimates of the
transit time of the messages from the server to the client. With
these the logical clock model must provide a representation of the
global clock to the highest accuracy attainable given the accuracy of
the local clock, the transit times from the server to the client, and 
using a model of the statistical variation of the transit times.

<p>
<A NAME="4.5"></A><h3>
4.5 Technology available for precise distributed clocks
</h3>
<p>


<p>
Until recently the availability of precise time sources and accurate
distribution mechansims required by precise distributed clocks has
been limited. With the advent of the Navstar Global Positioning
System (GPS) <B><A HREF="bibliography.html#Bib43">[43]</A></B>and high speed ATM networks these requirements may be more easily
fulfilled. The following sections describe the way in which all four
of the requirements can be fulfilled with the technology available to
Pandora systems.

<p>
<A NAME="4.5.1"></A><h4>
4.5.1 Navstar GPS --- a precise time source
</h4>
<p>


<p>
The Navstar GPS is a satellite-based radio-positioning, navigation and
time distribution system. Navstar GPS receivers provide a high accuracy
time anywhere in the world, in a small unit (10cm by 10cm, or smaller)
for a few hundred British pounds, provided a suitable position for its
small aerial is accessible. The installation at Olivetti Research
Laboratories, Cambridge, has the aerial placed on the roof with the
receiver inside the building.

<p>
<A NAME="4.5.1.1"></A><h5>
4.5.1.1 Overview of Navstar GPS
</h5>
<p>


<p>


<p>
The Navstar Global Posistioning System consists of three parts. The
first is a set of satellites in approximately circular
orbits. Originally twenty-one satellites were planned for the system,
using three satellites in each of six orbital planes with three
spare satellites. Presently there are twenty-five satellites, with
four satellites in each of the orbital planes. Each satellite
transmits on two radio frequencies (1575.42MHz and 1227.60MHz),
modulating the signal with a ranging code. Superimposed on these
signals is data relevant to the satellite, including clock information
and its ephemeris. Each satellite contains an atomic clock (some use
caesium, others rubidium), and receives data from the ground-based
control system to provide a correct ephemeris.

<p>
The second part of the system is the ground-based control system. This consists of
five monitor stations and ground antennas throughout the world. The
monitor stations use standard satallite receiver units to deduce range
information from the satellites, and this data is collated at the
master control station (in Colorado Springs, USA). The master control
station can estimate a new ephemeris and clock parameters for each
satellite, and this is transmitted to the satellites with the ground
antennas.

<p>
The final part of the system is the satellite receiver unit. This must
receive data from more than one satellite, preferably simultaneously,
in order to fix the position of the receiver's aerial.

<p>
From the information given by a single satellite a user can, if the user's
position is known, evaluate the UTC time to a high accuracy. From
the information given by four satellites a user can determine his position
and the UTC time. The positional accuracy is 100m for 95% of measurements,
but improves if the user takes an average of a large number of
measurements.

<p>
Many Navstar GPS receiver units track more than four satellites at
once, and choose the four strongest or best satellite signals. Some units have
twelve channels to track simultaneously twelve satellites, although it
is very rare for twelve to be visible. Other units use a smaller
number of channels with some dedicated to particularly strong
satellites, with the other channels tracking more than one satellite
using time division multiplexing.

<p>
<A NAME="4.5.1.2"></A><h5>
4.5.1.2 Precise timing calculation using Navstar GPS
</h5>
<p>


<p>
A precise UTC-synchronised clock can be accurately derived from the signals
transmitted by the Navstar GPS satellites. The method goes as follows:

<p>
The Navstar satellites transmit by modulating a radio frequency with a
ranging code. They use two radio frequencies, one which uses P-code
(Precise code), and the other uses C/A-code (Coarse/Acquisition code). At
present P-code receiving units may be bought, but are expensive. Also
AntiSpoofing may be implemented by the US Department of Defense in the
future, which encrypts the P-code signals into Y-code, making current
P-code receivers unusable.

<p>
The C/A-code is a 1.023 Mbps stream is a modulation of a code G(i,t),
a 1023 bit Gold code, where i is the satellite vehicle number. G(i,t) is
generated from two linear functions, G1(t) and G2(t).  These are both
generated using 10-stage shift registers.  G1(t) is defined by the
polynomial 1+x^3+x^10; G2(t) is defined by taking the pattern generated
by 1+x^2+x^3+x^6+x^8+x^9+x^10; G(i,t) is then the exclusive-or of
G1(t) and G2'(i,t). G2'(i,t) is generated by exclusive-oring two different
taps of the G2(t) shift register, dependent on the satellite number. As G1
and G2 both repeat after 1023 cycles, so does G. The data to be transmitted
modulates the G code at 50Hz. If a data 1 bit is to be transmitted then the
inverse G code is transmitted for that 50th of a second, else the normal G
code is transmitted.

<p>
The receiver can lock onto the sequence for a specific satellite vehicle by
genearating the appropriate Gold code G(i,t), and multiplying the data in
the received band by that signal. If there is a correlation (positive or
negative) after a data-bit time then the receiver has locked onto that
satellite. If there is no correlation the receiver must try again
after slipping by 1 Gold code bit time. In this way it can take 1023 cycles
of integration, each integration taking 1023 gold-bit times. The satellite
receiver must do this for a few frequencies around the satellites
transmitting frequency, as the received signal will have a Doppler shift, of
up to 4 kHz.

<p>
The data transmitted by the satellite using the modulated Gold code
contains:

<p>
<UL>


<p>
<LI>Satelllites' health

<p>
Information on the health of all satellites.

<p>
</LI>
<LI>Antispoof flags for each satellite

<p>
Antispoof flags indicate which satellites are using Y-code and not
P-code, and so cannot be used for precise positioning by a commercial
Navstar receiver unit.

<p>
</LI>
<LI>The satellite almanac

<p>
 This is reduced precison ephemerides for all the satellites. It is
used to help the Navstar receiving unit search for visible
satellites. The health of the satellites is used in the search 
to mask out satellites which are currently invalid or not in orbit.

<p>
</LI>
<LI>Accurate satellite ephemeris

<p>
The accurate ephemeris for the satellite transmitting, given to the
satellite by the master control station.

<p>
</LI>
<LI>Ionospheric data

<p>
The ionospheric data provides information for the ionospheric model
corrections in the receiver positioning algorithm.

<p>
</LI>
<LI>Week number and time of week in seconds

<p>
The week number is the number of weeks since 6th January 1980. This is in a
sense in units of GPS weeks, where each GPS week consists of
60*60*24*7 seconds. The time of the week in seconds is then always
between 0 and 60*60*24*7-1. GPS time does not allow for leap seconds
--- it increases steadily at one second per second. The offset between
GPS time and UTC accounts for leap seconds in UTC.

<p>
</LI>
<LI>UTC data

<p>
The UTC data provide information for converting GPS time to UTC time.

<p>
</LI>
<LI>A 22-ASCII character message.

<p>
The 22-character ASCII messages are usually junk. However, examples which
have been used and logged are: ``AIR FORCE 2SOPS TEST '' and ``2 SOPS
FALCON AFB TEST''.

<p>
</LI>
</UL>


<p>
The time data distributed by a satellite only has the precision of a
second. To generate accurate timing and positioning, the relative code
phases of more than one satellite are calculated. The signal
transmitted by a satellite is synchronised to its internal atomic
clock, starting a gold code sequence precisely at the start of a
second. The code phases at the receiver of signals from different
satellites will be different, as the distances and hence delays
between the receiver and the satellites will be different. The
relative code phases then provide accurate information as to the
relative distances of the satellites. With four satellites being
received the relative code phases give enough information for the
position of the receiver to be triangulated. Knowing the position of
the receiver and a fairly accurate knowledge of the time gives a very
precise estimate of the distances to the satellites, which can be used
to improve the accuracy of the knowledge of the time to greater than
the time taken by one Gold code bit, i.e. under a microsecond.

<p>
<A NAME="4.5.2"></A><h4>
4.5.2 Consistent local clocks
</h4>
<p>


<p>
A consistent local clock is a hardware counter which increments
approximately at a known rate, where the rate does not vary over short
time periods (i.e. a few seconds), which can be read by the
microprocessor in a system. If the frequency is fairly constant, the
logical clock model may calculate its value accurately. The counter
must be quickly accessible by processes running on the microprocessor
when distribution server messages arrive, so operating system support
for the local clock may also be required. These two areas are discussed in
more detail in the following sections:

<p>
<A NAME="4.5.2.1"></A><h5>
4.5.2.1 Hardware support
</h5>
<p>


<p>
Most microprocessors which may be used in networked systems do not
contain any readable clocks at all. Those microprocessors which do not
may have extra clock circuitry added in the surrounding system to provide timestamping
and timeout management facilities.

<p>
In the case of the Pandora box, each card contains a transputer, which
contains a microsecond clock linked to the processor clock signal,
which in turn is derived from a quartz crystal oscillator
IQEXO-3C. This provides a fairly constant rate if the temperature of
the oscillator does not vary much, and even if it does the maximum
variation is 100 parts per million (<B><A HREF="bibliography.html#Bib34">[34]</A></B>). Due to the
thermal mass of the oscillator its temperature will not change much
over a few seconds, so the frequency fulfils the stability criterion.

<p>
The new multimedia system being designed at the Olivetti Research
Laboratory in Cambridge uses boards based on the ARM microprocessor,
which does not contain a clock. However, the boards do supply a UART
which can provide millisecond counters, which may be used for a clock.
This limits the precision of the local clock on these boards to a
millisecond at best. Hence there is no point distributing a clock to an
Atmos board to greater precision than a millisecond. If the boards
were to be upgraded to include a microsecond clock, then the clock
distribution to these boards should be to that level of precision and
accuracy, if possible.

<p>


<p>
<A NAME="4.5.2.2"></A><h5>
4.5.2.2 Operating system support
</h5>
<p>


<p>
When a message arrives from the clock distribution server at the client
the transit time of that message must be determined, and the local
clock time of the arrival must be recorded. (The transit time should
equal the time between the clock distribution server sending the
message and the local clock being read.) Either the operating system
must provide this functionality itself, or it must allow a suitable
process to run sufficiently fast, to perform this operation accurately

<p>
The transputers in the Pandora box do not run an operating system:
the transputers include hardware scheduling which is used to manage
the running of the Pandora processes. The scheduling provides facilities
for waking up processes when messages arrive. The process switching
time is below a microsecond (if a high priority process is
interrupting a low priority process, or if the processor was
previously idle --- high priority processes are not interruptable),
and so it fulfils all the requirements described above, provided high
priority processes are wisely used by the programmer.

<p>
Other operating systems, however, tend to have longer timescales for
process switching, so interrupt handling would be the only path to
take. Unfortunately, if this path is followed by too many clients of
the operating system then the interrupt decoding mechanism adds
undesirable delay prior to the reading of the local clock, hence
decreasing the accuracy of the local knowledge of the global clock.

<p>
<A NAME="4.5.3"></A><h4>
4.5.3 Accurate distribution mechanisms
</h4>
<p>


<p>
As described above, the transit time of messages from a clock
distribution server to a client needs to be calculated to an accuracy
at least as high as the precision of the local clock, if that
precision is to be fully utilised. This requires support from the
physical network layer, either explicitly or by the nature of the
network's design. The different support supplied by different networks
is described in the sections below. The network types broadly split
into two with respect to the accuracy of transit time calculation
between those networks where the forward and return paths in a
connection have the same bandwidths and distances, and those which do
not. In the former (e.g. Ethernet), network transit times can be
calculated by sending messages on both paths and averaging. In the
latter (e.g. ring networks), the network transit time of data in the
different directions may not be related, hence limiting the accuracy
achievable, and requiring a more intelligent approach.

<p>
<A NAME="4.5.3.1"></A><h5>
4.5.3.1 Ethernet
</h5>
<p>


<p>
The transit times for packets on an Ethernet can be calculated
accurately in three stages. The first is calculating the time between
the transmission being requested and the transmitter succesfully
starting the transmission. The data then takes a fixed time to arrive
at the destination. The third stage is calculating the time between
the packet arriving at the destination and the packet being presented
to the operating system.

<p>
The first calculation can be performed by the network interface at the
transmitter using its local clock, reading the value at the time of
the request and the time of the transmission. The third calculation
can be performed by the network interface at the receiver using its
local clock. The second calculation can be performed beforehand, as it
corresponds to the network transit time for a block of data of the
size of the message from the soure to the destination. Due to the
physical nature of the Ethernet, the network transit time is the same
in both directions. So sending a message from source to destination
and back again takes two network transit times, plus values deducible
from the local clocks of the two network interfaces. Deducing and
removing these values and dividing by two gives an accurate estimate
of the network transit time for the message.

<p>
If an Ethernet is split into multiple segments, with bridges in
between, the symmetrical transmission nature may not be retained, so
reducing the accuracy of distribution. This accuracy can be recovered
if the bridge is intelligent with regard to the time messages --- it
can inform both client and server of the delay in a particular message
due to the bridge, if it too contains a local clock.

<p>
Most Ethernet interfaces do not provide the accurate time information
required for the first or third calculation stages, hence limiting
the accuracy of the whole calculation, and the accuracy of the
distributed clock. The result should still be accurate to under a
millisecond, which is more than good enough for Pandora. Unfortunately
the other properties of the Ethernet (bandwidth and media access) do
not support the multimedia requirements of Pandora, and so an Ethernet
network card for Pandora will never exist.

<p>
<A NAME="4.5.3.2"></A><h5>
4.5.3.2 ATM ring networks (CFR and CBN)
</h5>
<p>


<p>


<p>
For highest accuracy, any time messages whose transit times need to be
calculated should be a single 32-byte packet long. The transit time
calculation for the ring networks can then also be split into three
stages: time to transmission of the packet; time of transit of
the packet on the ring; time between packet reception and it
being presented to the operating system. The CMOS CFR chip provides
single packet FIFOs for transmission and reception, and signals to
its controller when the FIFOs become empty or full respectively. If
the local clock is read when these events occur, the first and third
stages of the calculation can be made accurate. The CBN uses much
deeper FIFOs (2048 packets), and so more care must be taken. One
possibility is to attempt to ensure that all other traffic is idle;
assume insertion time into the FIFO equals the start of network
transit; read the time when the receive FIFO becomes non-empty. This
solution introduces some inaccuracy, but it can be guaranteed to be
within certain bounds.

<p>
In both cases, the second stage, the ring transit time, is harder to
calculate. This is due to the different paths taken by traffic going
in opposite directions beween the two stations. If a packet is sent
from a source to destination, then from destination to source, the
packet will have spent one ring revolution of time on the ring. If the
transit time is taken to be half of this, the accuracy of the
calculation is one half of a ring revolution time. This accuracy may
be improved if the ordering of stations on a ring can be deduced, as
the ring revolution time is effected by the buffering of ring data
inside the stations. Unfortunately the ordering of stations on a ring
cannot be deduced just by using the ring itself.

<p>
On any CFR the ring revolution time is under 100 microseconds, and so
the accuracy of a distributed clock available to CFR-based Pandora
boxes should be better than 50 microseconds.

<p>
<A NAME="4.5.3.3"></A><h5>
4.5.3.3 ATM packet switch networks
</h5>
<p>


<p>


<p>
As for the ATM ring networks, it is best to use single cells to help
accurate transit time calculation of transmission of a message in an
ATM switch network. As with the CBN, FIFOs for transmission and
reception may be many cells deep, so a similar solution may be
adopted.

<p>
However, the second stage of the calculation, that of network transit
time, is not as easily performed with a switch fabric as either of the
network types described above. Firstly, the forward and return paths
from server to client may not be the same, so using the echoing method
described for Ethernet may not be applicable. Even for networks for
which both paths are the same length, the network
transit time for packets sent at different moments will be effected by
the switching times for those packets, which in turn is effected by
the loading of the switches at those moments. Hence the network transit
time for two packets along the same path may be different, and not
calculable by the receiver or transmitter.

<p>
The switching elements could provide help, timestamping with a local
clock on both reception and transmission of cells that they switch.
This may lower the overall performance of the switch, and so is
undesirable. The only alternative is to apply some statistical knowledge to the
handling of network transit times.

<p>
Depending on the statistical nature of the transit times of cells over
the ORL ATM switch network under normal networking loadings,
Pandora boxes connected to such a network may be able to have
distributed clocks more accurate than those connected to the CFR.

<p>
<A NAME="4.5.4"></A><h4>
4.5.4 Logical clock models
</h4>
<p>


<p>


<p>
Logical clock models are the basis of the software in any distributed
clock system. Only a small amount of research was performed into
logical clock models, as highly sophisticated models were deemed
unnecessary if the transit time of clock distribution messages could
be accurately determined, and therefore outside the scope of the
research.

<p>
In this research logical clock models are considered to consist of
four parts:

<p>
<UL>


<p>
<LI>A clock message filter

<p>
In an ideal system the transit time of messages from the server to the
client in a distributed clock system would be determinable to an
accuracy equal to the precision of the distributed clock. However, in
real systems there can be errors in the transit time calculations, or
in reading the local clock values corresponding to the arrival of the
messages from the server. In these cases a large error could affect
the stability of the logical clock model. So messages with
unexpectedly large transit times or unlikely local clock arrival
values may be filtered out. This filter depends on the message
distribution system, and in some logical clock models may never need
to filter messages as the clock correction unit may perform weighting
or filtering of the messages according to their distribution times.

<p>
</LI>
<LI>An offset detector

<p>
The offset detector takes the incoming clock messages and compares the
global time derived from that message using the transit time, local
clock arrival values, and the local-to-global clock conversion parameters
of the model, with the global time of its transmission given in the
message. The offset between the locally believed transmission time and
that given in the message is fed into the clock correction unit.

<p>
</LI>
<LI>Clock correction unit

<p>
The clock correction unit adjusts the local-to-global clock conversion
parameters for the model according to offsets it receives from the
offset detector. It may also make use of the message distribution
time, to weight the correction according to the believed accuracy of the
message.

<p>
</LI>
<LI>Clock reading

<p>
The logical clock model must also provide a mechanism for reading its
derived global clock. This will involve using the local clock value
and the clock conversion parameters. In returning the global time it
should also be able to describe the precision and accuracy of the
time.

<p>
</LI>
</UL>


<p>
In the course of the research a few clock models were experimented
with, and they are described below. For an examination of the
performance of the clock models, see section <A HREF="#5.3">5.3</A>.

<p>
<A NAME="4.5.4.1"></A><h5>
4.5.4.1 Initial experiments
</h5>
<p>


<p>
Initial experiments used a simple clock model.  A difference in
microseconds between the local clock value and the believed global
clock was stored in a shared 32-bit word. This was updated according
to frequency and phase error values derived from the clock correction
unit.

<p>
No clock message filter was used; the clock correction unit used a
long-term average to calculate the frequency error of the local clock
and the phase error was set to the offset detected between the clocks.
On the receipt of a message, the clock correction unit calculated the
number of microseconds by which the difference value would have to be
adjusted in a single second, and from this deduced the interval
between single microsecond adjustments for the difference value.

<p>
<A NAME="4.5.4.2"></A><h5>
4.5.4.2 NTP Fuzzball logical clock
</h5>
<p>


<p>
The above clock is not very stable, and can be easily improved on. The
Fuzzball <B><A HREF="bibliography.html#Bib18">[18]</A></B> logical clock, as used in the Network Time
Protocol (<B><A HREF="bibliography.html#Bib19">[19]</A></B>, <B><A HREF="bibliography.html#Bib20">[20]</A></B>), was
investigated next. This maintains a frequency error, phase error,
compliance, and difference between the local clock and the believed
global clock. The compliance is a measure of how close the derived
clock is to the global clock, and is determined by averaging the
offsets received from the offset detector over a period of time. The
frequency error is adjusted using the compliance as a scaling factor
--- if the clocks are not synchronised (absolute value of compliance
large), the frequency error will be adjusted more than if the clocks
are believed to be close to synchronisation (compliance near zero).
The phase error at the time a message is received is set to the offset
detected.

<p>
At regular intervals the difference between the local clock and the
believed global clock is adjusted according to the frequency error and
the phase error. At each of these stages the phase error is reduced,
so that it asympotitically recovers the last offset detected.

<p>


<p>
<A NAME="4.5.4.3"></A><h5>
4.5.4.3 Enhanced fuzzball logical clock
</h5>
<p>


<p>


<p>
To improve the capture range and frequency accuracy of the Fuzzball
logical clock (limited because of the 32-bit precision used in the
implementation) it was enhanced. The frequency error was adjusted to
use as many of the 32-bits as it could, using a divisor like an
exponent to provide a pseudo-floating point number. The real frequency
error is the frequency error divided by the divisor. The divisor is
decreased only if the frequency error would overflow its 32-bit word.
It is doubled, and the frequency error halved, only when the
compliance remains small for a period of tens of seconds, and then
only if the frequency error will not overflow. The clock difference
and phase error are stored to a precision of 1024ths of a microsecond.
In some internal calculations (for the frequency error adjustments)
64-bit integer arithmetic is used.

<p>
To ensure a monotonically increasing clock the clock difference
adjustment processes of the above two clock models were combined, so
that at suitable intervals the clock difference would be adjusted by
one microsecond (as in the initial implementation), and at regular
intervals a new adjustment would be calculated and the phase error
reduced (as in the Fuzzball logical clock).

<p>
Another enhancement was added to improve the start-up time of the
model. This uses the global and local time differences between the
first two messages received from the server to calculate a rough value
for the frequency error of the local clock.

<p>

<p>
<center><A HREF="experimentation_for_global_clocks.html">Chapter 5 : Experimentation for global clocks</A>
</body></html>
